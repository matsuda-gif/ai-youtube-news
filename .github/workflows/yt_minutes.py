# yt_minutes.py
# ç›®çš„ï¼š
#  - ç›´è¿‘HOURS_WINDOWæ™‚é–“ã®æ–°ç€å‹•ç”»ã‚’YouTube Data APIã§å–å¾—
#  - ã€Œè­°äº‹éŒ²ã‚¹ã‚¿ã‚¤ãƒ«ã€ã«æ•´å½¢ã—ã¦Slackã«æŠ•ç¨¿
#
# å‰æï¼ˆGitHub Secretsï¼‰:
#  - YT_API_KEY, SLACK_WEBHOOK_URL, CHANNEL_IDS (UC...ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š)
# ä»»æ„ï¼ˆSecrets or envï¼‰:
#  - HOURS_WINDOW (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ24), MAX_PER_CHANNEL (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ10)

import os, re, requests
from datetime import datetime, timedelta, timezone
from itertools import islice

API_KEY = os.environ["YT_API_KEY"]
SLACK_WEBHOOK = os.environ["SLACK_WEBHOOK_URL"]
CHANNEL_IDS = [c.strip() for c in os.environ["CHANNEL_IDS"].split(",") if c.strip()]
YAPI = "https://www.googleapis.com/youtube/v3"

HOURS_WINDOW = int(os.environ.get("HOURS_WINDOW", "24"))
MAX_PER_CHANNEL = int(os.environ.get("MAX_PER_CHANNEL", "10"))
JST = timezone(timedelta(hours=9))

def now_utc() -> datetime:
    return datetime.now(timezone.utc)

def to_iso_z(dt: datetime) -> str:
    return dt.astimezone(timezone.utc).isoformat(timespec="seconds").replace("+00:00", "Z")

def to_jst_str(iso_z: str) -> str:
    dt = datetime.fromisoformat(iso_z.replace("Z","+00:00")).astimezone(JST)
    return dt.strftime("%Y-%m-%d %H:%M")

def http_get(url: str, **params):
    params["key"] = API_KEY
    r = requests.get(url, params=params, timeout=30)
    r.raise_for_status()
    return r.json()

def get_uploads_pid(channel_id: str) -> str | None:
    r = http_get(f"{YAPI}/channels", part="contentDetails", id=channel_id)
    items = r.get("items", [])
    if not items: return None
    return items[0]["contentDetails"]["relatedPlaylists"]["uploads"]

def list_recent_video_ids(uploads_pid: str, published_after_z: str) -> list[str]:
    r = http_get(
        f"{YAPI}/playlistItems",
        part="contentDetails",
        playlistId=uploads_pid,
        maxResults=min(MAX_PER_CHANNEL, 50)
    )
    ids = []
    for it in r.get("items", []):
        vid = it["contentDetails"]["videoId"]
        pub = it["contentDetails"].get("videoPublishedAt")
        if pub and pub >= published_after_z:
            ids.append(vid)
    return ids

def chunked(iterable, size):
    it = iter(iterable)
    while True:
        chunk = list(islice(it, size))
        if not chunk:
            return
        yield chunk

def fetch_videos_meta(video_ids: list[str]) -> list[dict]:
    items = []
    for chunk in chunked(video_ids, 50):
        r = http_get(
            f"{YAPI}/videos",
            part="snippet,statistics",
            id=",".join(chunk)
        )
        items.extend(r.get("items", []))
    return items

KEYWORDS = {
    "multimodal":"ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«","vision":"ç”»åƒ/å‹•ç”»","video":"ç”»åƒ/å‹•ç”»","audio":"éŸ³å£°",
    "agent":"ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ","tool":"ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ","safety":"å®‰å…¨æ€§",
    "copyright":"è‘—ä½œæ¨©","regulation":"è¦åˆ¶","construction":"å»ºè¨­/æ–½å·¥",
    "marketing":"å–¶æ¥­/ãƒãƒ¼ã‚±","open-source":"OSS","finance":"é‡‘è"
}

def make_tags(title: str, desc: str) -> list[str]:
    text = f"{title}\n{desc}".lower()
    tags = [v for k,v in KEYWORDS.items() if k in text]
    return tags[:5] or ["ä¸€èˆ¬ãƒˆãƒ”ãƒƒã‚¯"]

def normalize_text(s: str) -> str:
    s = s.strip()
    s = re.sub(r"\s+", " ", s)
    return s

def bullets_from_description(desc: str, max_items: int = 3) -> list[str]:
    """
    è¶…ç°¡æ˜“ï¼šèª¬æ˜æ¬„ã‹ã‚‰ç®‡æ¡æ›¸ãå€™è£œã‚’æŠ½å‡ºã€‚
    - æ”¹è¡Œ/ãƒ»/.-ã§åˆ†å‰²ã—ã€çŸ­ã„æ–‡ã‚’å‰Šé™¤ã—ã¦ä¸Šä½3ä»¶ã‚’è¿”ã™
    - LLMæœªä½¿ç”¨ï¼ˆ0å††é‹ç”¨ãƒ»è¦ç´„é †å®ˆï¼‰
    """
    if not desc:
        return []
    raw = desc.replace("\r","").split("\n")
    parts = []
    for line in raw:
        line = line.strip(" ãƒ»-â€¢\t")
        if not line: continue
        # å¥ç‚¹ã§å¢—ã‚„ã™ï¼ˆè‹±èªã«ã‚‚å¯¾å¿œè»½ã‚ï¼‰
        fragments = re.split(r"[ã€‚.!?ãƒ»â€¢\-]+", line)
        for f in fragments:
            f = normalize_text(f)
            if len(f) >= 8:  # ã‚ã¾ã‚ŠçŸ­ã„ã®ã¯é™¤å¤–
                parts.append(f)
    # å…ˆé ­ã‹ã‚‰3ä»¶
    return parts[:max_items]

def build_minutes_text(metas: list[dict]) -> str:
    date_str = datetime.now(JST).strftime("%Y-%m-%d")
    lines = [f"ğŸ“„ AIãƒˆãƒ¬ãƒ³ãƒ‰ç¤¾å†…å ±ï¼ˆ{date_str}ï¼‰", ""]
    for idx, it in enumerate(metas, 1):
        sn = it["snippet"]
        title = sn.get("title", "(no title)")
        url = f"https://www.youtube.com/watch?v={it['id']}"
        chname = sn.get("channelTitle", "(unknown)")
        pub_jst = to_jst_str(sn["publishedAt"])
        desc = sn.get("description", "")
        tags = " ".join([f"#{t}" for t in make_tags(title, desc)])
        bullets = bullets_from_description(desc, 3) or [normalize_text(desc)[:100] + "â€¦"] if desc else ["ï¼ˆèª¬æ˜ãªã—ï¼‰"]

        lines.append(f"ã€è­°é¡Œ{idx}ã€‘{title}")
        lines.append(f"- æ—¥æ™‚ï¼š{pub_jst} JST")
        lines.append(f"- ç™ºè¡¨è€…ï¼š{chname}")
        lines.append(f"- æ¦‚è¦ï¼š")
        for b in bullets:
            lines.append(f"   ãƒ»{b}")
        lines.append(f"- URLï¼š{url}")
        lines.append(f"- ã‚¿ã‚°ï¼š{tags if tags else 'ï¼ˆãªã—ï¼‰'}")
        lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        lines.append("")
    return "\n".join(lines)

def post_to_slack_text(text: str):
    payload = {"text": text}
    r = requests.post(SLACK_WEBHOOK, json=payload, timeout=30)
    r.raise_for_status()

def main():
    published_after_z = to_iso_z(now_utc() - timedelta(hours=HOURS_WINDOW))
    all_ids = set()
    for ch in CHANNEL_IDS:
        upid = get_uploads_pid(ch)
        if not upid: continue
        all_ids.update(list_recent_video_ids(upid, published_after_z))

    if not all_ids:
        # æ–°ç€ãªã—é€šçŸ¥ï¼ˆå¿…è¦ãªã‘ã‚Œã°returnï¼‰
        date_str = datetime.now(JST).strftime("%Y-%m-%d %H:%M")
        post_to_slack_text(f"ğŸ“„ AIãƒˆãƒ¬ãƒ³ãƒ‰ç¤¾å†…å ±ï¼šæ–°ç€ãªã—ï¼ˆ{date_str} JST, éå»{HOURS_WINDOW}hï¼‰")
        return

    metas = fetch_videos_meta(list(all_ids))
    metas.sort(key=lambda x: x["snippet"]["publishedAt"], reverse=True)
    text = build_minutes_text(metas)
    post_to_slack_text(text)

if __name__ == "__main__":
    main()
